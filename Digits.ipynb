{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Loading data\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x216cabdb490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2 Visualizing the Data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(x_train[0], cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras library expects the input to the convolutional neural network (CNN) to have four (4) dimensions, so you will add the fourth dimension as 1 using the reshape function.\n",
    "The first three (3) dimensions represent the number of samples, as well as the width and length of each sample, respectively.\n",
    "It is also better to normalize the input to be from 0 to 1, which is simple in this case. Grayscale images of MNIST contains pixels, and each pixel has a grayscale value from 0 to 255.\n",
    "You can divide the input by 255 (maximum value for grayscale colours) to normalize it (i.e., make the values between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Prepare data for CNN\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)/255\n",
    "# Reshape logic (# of samples, image width, image height, 1)\n",
    "# We add the extra dimension because Keras requires four for CNN operations, hence the one\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)/255\n",
    "# The normalization of images in CNNs is a crucial step to train it effectively\n",
    "#The grayscale values are encoded to a float of [0, 1].\n",
    "# ie. 255/255 --> 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 Set up CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 28)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4732)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               605824    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 607,394\n",
      "Trainable params: 607,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()#for adding layers together\n",
    "\n",
    "#I) Add an \"INPUT\" Convolutional Layer\n",
    "from keras.layers import Conv2D\n",
    "model.add(Conv2D(filters= 28, kernel_size=(3,3), input_shape=(28,28,1), activation='relu'))\n",
    "#Syntax #of outpits, windowsize(x,y), use input shape from reshape\n",
    "\n",
    "#II) Add a Pooling Layer\n",
    "from keras.layers import MaxPooling2D\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "##IIb) Add a flattening layer\n",
    "from keras.layers import Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#III) Add a Fully Connected Layer\n",
    "from keras.layers import Dense\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "#note how a fully connected layer is the same as a traditional ANN layer\n",
    "\n",
    "#IV) Add an \"OUTPUT\" Fully Connected Layer\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Configuring model for training\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "##actually running the model, for the training\n",
    "#model.fit(...)\n",
    "## running the model to generate predictions for input samples... PERFORMS THE TRAINING\n",
    "#model.predict() ----> use after training\n",
    "##Running the model to get loss and whatever metrics were specificied in the compile command\n",
    "# model.evaluate(input to be predicted, target value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1588 - accuracy: 0.9531\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0546 - accuracy: 0.9835\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0367 - accuracy: 0.9885\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0236 - accuracy: 0.9926\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0163 - accuracy: 0.9949\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0114 - accuracy: 0.9960\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0085 - accuracy: 0.9970\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 2.1049e-04 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 1.5052e-05 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 3.3161e-06 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 1.6598e-06 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 7.8703e-07 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 3.7132e-07 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.5861e-07 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 7.8139e-08 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 6.3217e-05 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 6.7636e-06 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 1.6177e-06 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 6.0493e-07 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 3.3218e-07 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 1.7382e-07 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 8.3384e-08 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 4.0698e-08 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 2.1325e-08 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 1.1520e-08 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 5.5711e-04 - accuracy: 0.9999\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 4.0544e-04 - accuracy: 0.9998\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 9.2937e-04 - accuracy: 0.9998\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 9.0581e-04 - accuracy: 0.9997\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 8.7826e-04 - accuracy: 0.9997\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 9.1579e-04 - accuracy: 0.9997\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 5.7712e-04 - accuracy: 0.9999\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 5.9028e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 8.4333e-04 - accuracy: 0.9997\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.5356e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 9.9784e-04 - accuracy: 0.9998\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 3.9951e-04 - accuracy: 0.9999\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 7.5450e-04 - accuracy: 0.9998\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 7.0439e-04 - accuracy: 0.9998\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.7752e-05 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 4.9565e-07 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3854e-07 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 1.4120e-07 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 7.9594e-08 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 4.3795e-08 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 2.4195e-08 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.2819e-08 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 6.9896e-09 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 3.8107e-09 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 2.0703e-09 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.1285e-09 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 7.0532e-10 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 3.9339e-10 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 2.9206e-10 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.7683e-10 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.4901e-10 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.2120e-10 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.0331e-10 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 7.7486e-11 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 7.7486e-11 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 6.5565e-11 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216f37b8410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)#CNNs should no have batfches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9888\n",
      "loss:  0.1447279453277588\n",
      "accuracy:  0.9887999892234802\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"loss: \", loss)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
